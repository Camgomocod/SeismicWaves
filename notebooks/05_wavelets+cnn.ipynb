{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e8b3a235",
   "metadata": {},
   "source": [
    "# Wavelet Transform\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dde987ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from obspy import read\n",
    "from tqdm import tqdm\n",
    "import scipy.stats as stats\n",
    "import matplotlib.pyplot as plt\n",
    "import pywt\n",
    "\n",
    "# Paths\n",
    "augmented_data_path = '/mnt/c/Users/Usuario/Documents/Studies/GicoProject/SeismicWaves/data/procesed/used_data/training_augmented'\n",
    "features_path = '/mnt/c/Users/Usuario/Documents/Studies/GicoProject/SeismicWaves/data/procesed/features'\n",
    "\n",
    "# Create features directory if it doesn't exist\n",
    "if not os.path.exists(features_path):\n",
    "    os.makedirs(features_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9f61ef13",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_wavelet_features(signal, wavelet='db4', level=4):\n",
    "    \"\"\"Extract statistical features from wavelet decomposition of a signal.\n",
    "    Args:\n",
    "        signal: Input signal array\n",
    "        wavelet: Wavelet type to use\n",
    "        level: Decomposition level\n",
    "    Returns:\n",
    "        array: Feature vector containing statistical measures\"\"\"\n",
    "    # Perform wavelet decomposition\n",
    "    coeffs = pywt.wavedec(signal, wavelet, level=level)\n",
    "    \n",
    "    # Initialize feature list\n",
    "    features = []\n",
    "    \n",
    "    # Extract features from each coefficient level\n",
    "    for coef in coeffs:\n",
    "        # Statistical features\n",
    "        features.extend([\n",
    "            np.mean(coef),           # Mean\n",
    "            np.std(coef),            # Standard deviation\n",
    "            stats.skew(coef),        # Skewness\n",
    "            stats.kurtosis(coef),    # Kurtosis\n",
    "            np.percentile(coef, 75), # 75th percentile\n",
    "            np.percentile(coef, 25), # 25th percentile\n",
    "            np.max(coef),            # Maximum\n",
    "            np.min(coef),            # Minimum\n",
    "            np.sum(np.abs(coef)),    # L1 norm\n",
    "            np.sqrt(np.sum(coef**2)),# L2 norm\n",
    "            stats.entropy(np.abs(coef)), # Signal entropy\n",
    "            np.median(np.abs(coef))  # Median absolute deviation\n",
    "        ])\n",
    "        \n",
    "    return np.array(features)\n",
    "\n",
    "def process_seismic_files(data_path, arrival_times_csv):\n",
    "    \"\"\"Process all seismic files and extract wavelet features.\n",
    "    Args:\n",
    "        data_path: Path to directory containing MSEED files\n",
    "        arrival_times_csv: Path to CSV with arrival times\n",
    "    Returns:\n",
    "        tuple: (features array, arrival times array, file names)\"\"\"\n",
    "    # Read arrival times\n",
    "    arrivals_df = pd.read_csv(arrival_times_csv)\n",
    "    \n",
    "    features_list = []\n",
    "    arrival_times = []\n",
    "    file_names = []\n",
    "    \n",
    "    print('Extracting wavelet features...')\n",
    "    for _, row in tqdm(arrivals_df.iterrows(), total=len(arrivals_df)):\n",
    "        file_path = os.path.join(data_path, row['augmented_file'])\n",
    "        \n",
    "        try:\n",
    "            # Read seismic signal\n",
    "            st = read(file_path)\n",
    "            signal = st[0].data\n",
    "            \n",
    "            # Extract features\n",
    "            features = extract_wavelet_features(signal)\n",
    "            features_list.append(features)\n",
    "            arrival_times.append(row['arrival_time'])\n",
    "            file_names.append(row['augmented_file'])\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f'Error processing {file_path}: {str(e)}')\n",
    "            continue\n",
    "    \n",
    "    return np.array(features_list), np.array(arrival_times), file_names\n",
    "\n",
    "def process_seismic_files_no_times(data_path):\n",
    "    \"\"\"Process seismic files and extract wavelet features without arrival times.\n",
    "    Args:\n",
    "        data_path: Path to directory containing MSEED files\n",
    "    Returns:\n",
    "        tuple: (features array, file names)\"\"\"\n",
    "    features_list = []\n",
    "    file_names = []\n",
    "    \n",
    "    # Get all MSEED files in directory\n",
    "    mseed_files = [f for f in os.listdir(data_path) if f.endswith('.mseed')]\n",
    "    \n",
    "    print('Extracting wavelet features...')\n",
    "    for filename in tqdm(mseed_files):\n",
    "        file_path = os.path.join(data_path, filename)\n",
    "        \n",
    "        try:\n",
    "            # Read seismic signal\n",
    "            st = read(file_path)\n",
    "            signal = st[0].data\n",
    "            \n",
    "            # Extract features\n",
    "            features = extract_wavelet_features(signal)\n",
    "            features_list.append(features)\n",
    "            file_names.append(filename)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f'Error processing {file_path}: {str(e)}')\n",
    "            continue\n",
    "    \n",
    "    return np.array(features_list), file_names\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dce38295",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting wavelet features...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 790/790 [00:40<00:00, 19.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted features shape: (790, 60)\n",
      "Number of processed files: 790\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Example usage:\n",
    "data_path = '/mnt/c/Users/Usuario/Documents/Studies/GicoProject/SeismicWaves/data/raw/test'\n",
    "X, files = process_seismic_files_no_times(data_path)\n",
    "\n",
    "# Save features and filenames\n",
    "output_path = '/mnt/c/Users/Usuario/Documents/Studies/GicoProject/SeismicWaves/data/procesed/features'\n",
    "np.save(os.path.join(output_path, 'wavelet_features_only_testing.npy'), X)\n",
    "pd.DataFrame({'file': files}).to_csv(\n",
    "    os.path.join(output_path, 'feature_files_only_testing.csv'), index=False)\n",
    "\n",
    "print(f'Extracted features shape: {X.shape}')\n",
    "print(f'Number of processed files: {len(files)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a984516",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e3f06a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting wavelet features...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/4989 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4989/4989 [03:34<00:00, 23.21it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted features shape: (4989, 60)\n",
      "Number of samples: 4989\n",
      "Features extracted per coefficient level: 12\n",
      "Total features for 4 levels: 60\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Process all files\n",
    "augmented_path = os.path.join(augmented_data_path, 'augmented')\n",
    "arrival_times_csv = os.path.join(augmented_data_path, 'arrival_times.csv')\n",
    "\n",
    "X, y, files = process_seismic_files(augmented_path, arrival_times_csv)\n",
    "\n",
    "# Save features and metadata\n",
    "np.save(os.path.join(features_path, 'wavelet_features.npy'), X)\n",
    "np.save(os.path.join(features_path, 'arrival_times.npy'), y)\n",
    "pd.DataFrame({'file': files}).to_csv(\n",
    "    os.path.join(features_path, 'feature_files.csv'), index=False)\n",
    "\n",
    "print(f'Extracted features shape: {X.shape}')\n",
    "print(f'Number of samples: {len(files)}')\n",
    "\n",
    "# Update the feature extraction info\n",
    "print('Features extracted per coefficient level:', 12)\n",
    "print('Total features for 4 levels:', 12 * (4 + 1))  # 4 detail + 1 approximation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "331c7440",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features for file 01010056.mseed:\n",
      "Feature vector length: 60\n",
      "\n",
      "First 10 features:\n",
      "[-2.26887150e-03  1.36387755e-01  2.11445763e+00  9.02215459e+01\n",
      "  1.74969649e-02 -1.97850397e-02  1.76067501e+00 -1.31033293e+00\n",
      "  1.88985862e+01  2.85151844e+00]\n",
      "\n",
      "Arrival time: 30.60s\n"
     ]
    }
   ],
   "source": [
    "# Show example of features for one file\n",
    "example_idx = 0\n",
    "print(f'Features for file {files[example_idx]}:')\n",
    "print('Feature vector length:', len(X[example_idx]))\n",
    "print('\\nFirst 10 features:')\n",
    "print(X[example_idx][:10])\n",
    "print(f'\\nArrival time: {y[example_idx]:.2f}s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2936c912",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forma de X: (4989, 60)\n",
      "Forma de y: (4989,)\n",
      "\n",
      "Primeros 5 elementos de X:\n",
      "[[-2.26887150e-03  1.36387755e-01  2.11445763e+00  9.02215459e+01\n",
      "   1.74969649e-02 -1.97850397e-02  1.76067501e+00 -1.31033293e+00\n",
      "   1.88985862e+01  2.85151844e+00  4.90902773e+00  1.87466164e-02\n",
      "  -4.68282065e-03  4.36041154e-01 -1.00966551e+00  3.50142234e+01\n",
      "   7.43629529e-02 -8.48785630e-02  3.57025540e+00 -3.56212458e+00\n",
      "   7.44136070e+01  9.11576754e+00  5.07205141e+00  8.28264720e-02\n",
      "   5.64923997e-02  1.62441522e+00  4.88074603e+00  1.10670185e+02\n",
      "   2.23716437e-01 -2.32970680e-01  2.68300654e+01 -1.51858868e+01\n",
      "   4.54496807e+02  4.78871929e+01  5.62304109e+00  2.28371860e-01\n",
      "   3.33488387e-05  1.16491400e+00 -5.91348512e-01  7.28446100e+01\n",
      "   1.35390393e-01 -1.25288355e-01  1.26437588e+01 -1.69246391e+01\n",
      "   6.01567335e+02  4.84525808e+01  6.10403926e+00  1.28995578e-01\n",
      "  -1.18978216e-05  1.56823783e-01 -9.33989454e-01  7.02097351e+01\n",
      "   2.04853454e-02 -1.97404723e-02  1.95495840e+00 -2.39828782e+00\n",
      "   1.75673647e+02  9.21664998e+00  6.91394816e+00  2.01186373e-02]\n",
      " [-2.78073911e-03  1.31386908e-01  1.97194159e+00  8.47180714e+01\n",
      "   1.73914060e-02 -1.98043740e-02  1.66836012e+00 -1.24163016e+00\n",
      "   1.86626542e+01  2.74719860e+00  4.92488746e+00  1.89794194e-02\n",
      "  -4.04438145e-03  4.15182662e-01 -9.96387607e-01  3.43010655e+01\n",
      "   7.87078891e-02 -8.55785640e-02  3.38306144e+00 -3.37535693e+00\n",
      "   7.23412199e+01  8.67961641e+00  5.09868660e+00  8.28520392e-02\n",
      "   5.46658550e-02  1.54269890e+00  4.84560726e+00  1.09643018e+02\n",
      "   2.30213017e-01 -2.22895235e-01  2.54233239e+01 -1.43896675e+01\n",
      "   4.40372299e+02  4.54792740e+01  5.65307839e+00  2.27238778e-01\n",
      "   4.41489196e-05  1.10511105e+00 -5.89324704e-01  7.24956452e+01\n",
      "   1.28934983e-01 -1.19759040e-01  1.19808272e+01 -1.60372543e+01\n",
      "   5.79545884e+02  4.59651809e+01  6.13390489e+00  1.25805948e-01\n",
      "  -1.23356931e-05  1.48794737e-01 -9.30173622e-01  6.98308067e+01\n",
      "   1.98003277e-02 -1.96806573e-02  1.85245693e+00 -2.27254191e+00\n",
      "   1.69187629e+02  8.74477698e+00  6.94216426e+00  1.97477541e-02]\n",
      " [ 7.01690447e-03  1.43728394e-01  2.12691936e+00  7.49080174e+01\n",
      "   2.41702330e-02 -2.07696069e-02  1.76624451e+00 -1.33278114e+00\n",
      "   2.17542970e+01  3.00815517e+00  5.00962437e+00  2.20897215e-02\n",
      "  -1.64237927e-03  4.36704361e-01 -1.01777622e+00  3.48523135e+01\n",
      "   8.13999749e-02 -7.82508967e-02  3.56858606e+00 -3.55995188e+00\n",
      "   7.49955563e+01  9.12917050e+00  5.08452950e+00  8.03226011e-02\n",
      "   6.38297538e-02  1.62470216e+00  4.87316402e+00  1.10620749e+02\n",
      "   2.28907246e-01 -2.17910985e-01  2.68384265e+01 -1.51715690e+01\n",
      "   4.53853184e+02  4.79036408e+01  5.61654119e+00  2.24692355e-01\n",
      "  -4.67675871e-04  1.16439617e+00 -5.92529615e-01  7.28881320e+01\n",
      "   1.30003263e-01 -1.24509670e-01  1.26476890e+01 -1.69280137e+01\n",
      "   6.02112469e+02  4.84310468e+01  6.10828156e+00  1.28185975e-01\n",
      "  -2.12634018e-04  1.57078457e-01 -9.74028372e-01  6.88163556e+01\n",
      "   2.42115903e-02 -2.49278539e-02  1.94735878e+00 -2.41084441e+00\n",
      "   1.88142164e+02  9.23162578e+00  7.04345344e+00  2.45201043e-02]\n",
      " [ 4.95318652e-03  1.08089806e-01  6.76946493e-01  1.78925549e+01\n",
      "   2.59214767e-02 -2.53102785e-02  6.72727573e-01 -7.78559480e-01\n",
      "   2.50276758e+01  2.34329341e+00  5.37874545e+00  2.55920848e-02\n",
      "  -2.13726744e-03  3.87532334e-01  2.97102655e-01  1.66994858e+01\n",
      "   1.34302319e-01 -1.26973936e-01  3.02161880e+00 -2.48973620e+00\n",
      "   1.02245272e+02  8.39268592e+00  5.53249019e+00  1.30336628e-01\n",
      "  -1.84671474e-02  1.20351184e+00 -7.35053160e-01  2.17897817e+01\n",
      "   3.58279117e-01 -3.76788132e-01  8.98613364e+00 -1.15170212e+01\n",
      "   6.11392336e+02  3.67262282e+01  6.19376512e+00  3.73615295e-01\n",
      "  -4.59995528e-04  7.16549085e-01  5.12237423e-02  2.46330961e+01\n",
      "   2.28383962e-01 -2.32447131e-01  7.54858748e+00 -8.08766148e+00\n",
      "   7.29819672e+02  3.08615683e+01  6.90263162e+00  2.31413748e-01\n",
      "  -1.94334647e-05  1.18638447e-01  3.35999434e-01  3.09023320e+01\n",
      "   3.90900068e-02 -3.81517114e-02  1.48575353e+00 -1.25993729e+00\n",
      "   2.37555885e+02  7.22039484e+00  7.59830720e+00  3.85905082e-02]\n",
      " [ 5.58398012e-03  1.24832997e-01  5.60219118e-01  1.90629747e+01\n",
      "   2.85865890e-02 -2.75337414e-02  7.97672649e-01 -9.23160619e-01\n",
      "   2.81323541e+01  2.70613761e+00  5.34763948e+00  2.82217202e-02\n",
      "  -2.93711762e-03  4.50919196e-01  3.17860601e-01  1.81470702e+01\n",
      "   1.46363010e-01 -1.40027766e-01  3.58282129e+00 -2.95215262e+00\n",
      "   1.15346824e+02  9.76549716e+00  5.49970138e+00  1.45330268e-01\n",
      "  -2.08509938e-02  1.39025909e+00 -7.82802396e-01  2.41838283e+01\n",
      "   4.06470213e-01 -4.23188230e-01  1.06551200e+01 -1.36560670e+01\n",
      "   6.85714238e+02  4.24247629e+01  6.16645337e+00  4.10516821e-01\n",
      "  -5.17589674e-04  8.24856575e-01  5.49725942e-02  2.75871766e+01\n",
      "   2.50967439e-01 -2.55328692e-01  8.95057972e+00 -9.58977544e+00\n",
      "   8.15893504e+02  3.55263412e+01  6.87762528e+00  2.53457455e-01\n",
      "  -2.02853577e-05  1.37386423e-01  3.59516500e-01  3.40930719e+01\n",
      "   4.31861666e-02 -4.21525851e-02  1.76170118e+00 -1.49394429e+00\n",
      "   2.66069039e+02  8.36140596e+00  7.56995287e+00  4.26432622e-02]]\n",
      "\n",
      "Primeros 5 elementos de y:\n",
      "[30.5999999 30.5999999 20.9999999 30.0999999 30.0999999]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Cargar los archivos\n",
    "features_path = '/mnt/c/Users/Usuario/Documents/Studies/GicoProject/SeismicWaves/data/procesed/features'\n",
    "X = np.load(os.path.join(features_path, 'wavelet_features.npy'))\n",
    "y = np.load(os.path.join(features_path, 'arrival_times.npy'))\n",
    "\n",
    "# Verificar las dimensiones\n",
    "print(f\"Forma de X: {X.shape}\")\n",
    "print(f\"Forma de y: {y.shape}\")\n",
    "\n",
    "# Ver los primeros elementos\n",
    "print(\"\\nPrimeros 5 elementos de X:\")\n",
    "print(X[:5])\n",
    "print(\"\\nPrimeros 5 elementos de y:\")\n",
    "print(y[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a417b9d0",
   "metadata": {},
   "source": [
    "## Procesamiento del conjunto de prueba\n",
    "\n",
    "Procesamos el conjunto de prueba usando las mismas funciones de extracción de características que usamos para el conjunto de entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0641d5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Procesando tiempos de llegada del conjunto de prueba...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2500 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_29978/1829780971.py:26: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  test_times_df = pd.concat([test_times_df, pd.DataFrame([{\n",
      "100%|██████████| 2500/2500 [00:21<00:00, 115.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tiempos de llegada guardados en /mnt/c/Users/Usuario/Documents/Studies/GicoProject/SeismicWaves/data/procesed/used_data/training_augmented/val/val_arrival_times.csv\n",
      "y /mnt/c/Users/Usuario/Documents/Studies/GicoProject/SeismicWaves/data/procesed/features/test_arrival_times.npy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>arrival_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>04010919.mseed</td>\n",
       "      <td>14.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>04020130.mseed</td>\n",
       "      <td>11.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>04021826.mseed</td>\n",
       "      <td>30.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>04031203.mseed</td>\n",
       "      <td>30.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>04040354.mseed</td>\n",
       "      <td>30.26</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             file  arrival_time\n",
       "0  04010919.mseed         14.84\n",
       "1  04020130.mseed         11.45\n",
       "2  04021826.mseed         30.93\n",
       "3  04031203.mseed         30.62\n",
       "4  04040354.mseed         30.26"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Definir rutas\n",
    "testing_data_path = '/mnt/c/Users/Usuario/Documents/Studies/GicoProject/SeismicWaves/data/procesed/used_data/testing'\n",
    "test_csv_path = '/mnt/c/Users/Usuario/Documents/Studies/GicoProject/SeismicWaves/data/raw/VT_P_training.csv'\n",
    "\n",
    "def process_arrival_times(data_path, data_name):\n",
    "    \"\"\"Procesa los tiempos de llegada para el conjunto de prueba.\"\"\"\n",
    "    # Leer CSV con tiempos de llegada de prueba\n",
    "    test_df = pd.read_csv(test_csv_path)\n",
    "    \n",
    "    # Preparar DataFrame para almacenar tiempos de llegada\n",
    "    test_times_df = pd.DataFrame(columns=['file', 'arrival_time'])\n",
    "    \n",
    "    print('Procesando tiempos de llegada del conjunto de prueba...')\n",
    "    for _, row in tqdm(test_df.iterrows(), total=len(test_df)):\n",
    "        file_id = row['archivo']\n",
    "        mseed_file = f\"{file_id:08d}.mseed\"\n",
    "        file_path = os.path.join(data_path, mseed_file)\n",
    "        \n",
    "        try:\n",
    "            # Leer señal y obtener tiempo relativo\n",
    "            st = read(file_path)\n",
    "            absolute_p_time = row['lec_p']\n",
    "            relative_p_time = absolute_p_time - st[0].stats.starttime.timestamp\n",
    "            \n",
    "            # Agregar al DataFrame\n",
    "            test_times_df = pd.concat([test_times_df, pd.DataFrame([{\n",
    "                'file': mseed_file,\n",
    "                'arrival_time': relative_p_time\n",
    "            }])], ignore_index=True)\n",
    "            \n",
    "        except Exception as e:\n",
    "            continue\n",
    "    \n",
    "    # Guardar tiempos de llegada\n",
    "    test_times_df.to_csv(os.path.join(features_path, f'{data_name}.csv'), index=False)\n",
    "    np.save(os.path.join(features_path, data_name), test_times_df['arrival_time'].values)\n",
    "    \n",
    "    print(f'Tiempos de llegada guardados en {data_path}/{data_name}.csv')\n",
    "    print(f'y {features_path}/test_arrival_times.npy')\n",
    "    \n",
    "    return test_times_df\n",
    "\n",
    "# Procesar tiempos de llegada\n",
    "test_times_df = process_arrival_times(testing_data_path, 'test_arrival_times')\n",
    "\n",
    "# Mostrar algunos ejemplos\n",
    "#print('\\nPrimeros 5 tiempos de llegada:')\n",
    "# print(test_times_df.head())\n",
    "\n",
    "\n",
    "val_data_path = '/mnt/c/Users/Usuario/Documents/Studies/GicoProject/SeismicWaves/data/procesed/used_data/training_augmented/val'\n",
    "val_times_df = process_arrival_times(val_data_path, 'val_arrival_times')\n",
    "val_times_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "08b2e5ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 317 entries, 0 to 316\n",
      "Data columns (total 2 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   file          317 non-null    object \n",
      " 1   arrival_time  317 non-null    float64\n",
      "dtypes: float64(1), object(1)\n",
      "memory usage: 5.1+ KB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 496 entries, 0 to 495\n",
      "Data columns (total 2 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   file          496 non-null    object \n",
      " 1   arrival_time  496 non-null    float64\n",
      "dtypes: float64(1), object(1)\n",
      "memory usage: 7.9+ KB\n"
     ]
    }
   ],
   "source": [
    "val_times_df.info()\n",
    "test_times_df.info()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wavePredict",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
