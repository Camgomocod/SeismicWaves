{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "926a39c2",
      "metadata": {
        "id": "926a39c2"
      },
      "source": [
        "# Training Model: Cnn + wavelets transform"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "id": "SAkblZbMZKOY",
        "outputId": "84b0b737-c932-4443-9da3-d6e695f162c0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "SAkblZbMZKOY",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install obspy"
      ],
      "metadata": {
        "id": "53jvg7KWrB0h"
      },
      "id": "53jvg7KWrB0h",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "99d53813",
      "metadata": {
        "id": "99d53813"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from obspy import read\n",
        "from tqdm import tqdm\n",
        "from sklearn.model_selection import train_test_split\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "4029eab8",
      "metadata": {
        "id": "4029eab8"
      },
      "outputs": [],
      "source": [
        "base_path = '/content/gdrive/MyDrive'\n",
        "\n",
        "\n",
        "\n",
        "train_augmented_data_path = f'{base_path}/Notebooks/SeismicWaves/training_augmented/augmented'\n",
        "train_data_path = f'{base_path}/Notebooks/SeismicWaves/training_augmented/train'\n",
        "val_data_path = f'{base_path}/Notebooks/SeismicWaves/training_augmented/val'\n",
        "test_data_path = f'{base_path}/Notebooks/SeismicWaves/training_augmented/testing'\n",
        "features_path = f'{base_path}/Notebooks/SeismicWaves/procesing'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "7ad52981",
      "metadata": {
        "id": "7ad52981",
        "outputId": "3b8f790c-6d6a-4867-c22d-866f60df2c09",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/content/gdrive/MyDrive/Notebooks/SeismicWaves/training_augmented/train/feature_files.csv'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-ed310122e1f4>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;31m# ------------------- Carga de Datos -------------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m \u001b[0mX_raw_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_wavelets_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_files\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0mX_raw_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_wavelets_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_files\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_data_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0mX_raw_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_wavelets_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_files\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_data_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-3-ed310122e1f4>\u001b[0m in \u001b[0;36mload_data\u001b[0;34m(data_path)\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;31m# Cargar señales crudas\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mraw_signals\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mfiles_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'feature_files.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Cargando señales desde {data_path}...'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mfile\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiles_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'file'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1024\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1619\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1620\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1622\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1879\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1880\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1881\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1882\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    871\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 873\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    874\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/gdrive/MyDrive/Notebooks/SeismicWaves/training_augmented/train/feature_files.csv'"
          ]
        }
      ],
      "source": [
        "\n",
        "# ------------------- Funciones de Carga -------------------\n",
        "def load_data(data_path):\n",
        "    # Cargar señales crudas\n",
        "    raw_signals = []\n",
        "    files_df = pd.read_csv(os.path.join(data_path, 'feature_files.csv'))\n",
        "    print(f'Cargando señales desde {data_path}...')\n",
        "    for file in tqdm(files_df['file']):\n",
        "        file_path = os.path.join(data_path, 'augmented', file)\n",
        "        st = read(file_path)\n",
        "        signal = st[0].data\n",
        "        raw_signals.append(signal)\n",
        "\n",
        "    X_raw = np.array(raw_signals)\n",
        "    X_raw = X_raw.reshape(X_raw.shape[0], -1, 1)  # Añadir dimensión para CNN\n",
        "\n",
        "    # Cargar características wavelets\n",
        "    X_wavelets = np.load(os.path.join(data_path, 'wavelet_features.npy'))\n",
        "\n",
        "    # Cargar tiempos de llegada\n",
        "    y = np.load(os.path.join(data_path, 'arrival_times.npy'))\n",
        "\n",
        "    return X_raw, X_wavelets, y, files_df\n",
        "\n",
        "# ------------------- Carga de Datos -------------------\n",
        "X_raw_train, X_wavelets_train, y_train, train_files = load_data(train_data_path)\n",
        "X_raw_val, X_wavelets_val, y_val, val_files = load_data(val_data_path)\n",
        "X_raw_test, X_wavelets_test, y_test, test_files = load_data(test_data_path)\n",
        "\n",
        "print('Formas:')\n",
        "print(f'Entrenamiento señales crudas: {X_raw_train.shape}')\n",
        "print(f'Validación señales crudas: {X_raw_val.shape}')\n",
        "print(f'Prueba señales crudas: {X_raw_test.shape}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "effc50e5",
      "metadata": {
        "id": "effc50e5"
      },
      "outputs": [],
      "source": [
        "# ------------------- Creación del Modelo -------------------\n",
        "def create_model(input_shape_raw, input_shape_wavelets):\n",
        "    # Entrada de señales crudas\n",
        "    raw_input = tf.keras.layers.Input(shape=input_shape_raw)\n",
        "    x1 = tf.keras.layers.BatchNormalization()(raw_input)\n",
        "    x1 = tf.keras.layers.Conv1D(32, 5, padding='same', activation='relu')(x1)\n",
        "    x1 = tf.keras.layers.BatchNormalization()(x1)\n",
        "    x1 = tf.keras.layers.MaxPooling1D(2)(x1)\n",
        "    x1 = tf.keras.layers.Conv1D(64, 5, padding='same', activation='relu')(x1)\n",
        "    x1 = tf.keras.layers.BatchNormalization()(x1)\n",
        "    x1 = tf.keras.layers.MaxPooling1D(2)(x1)\n",
        "    x1 = tf.keras.layers.Conv1D(128, 5, padding='same', activation='relu')(x1)\n",
        "    x1 = tf.keras.layers.BatchNormalization()(x1)\n",
        "    x1 = tf.keras.layers.GlobalAveragePooling1D()(x1)\n",
        "\n",
        "    # Entrada de características wavelets\n",
        "    wavelet_input = tf.keras.layers.Input(shape=input_shape_wavelets)\n",
        "    x2 = tf.keras.layers.BatchNormalization()(wavelet_input)\n",
        "    x2 = tf.keras.layers.Dense(128, activation='relu')(x2)\n",
        "    x2 = tf.keras.layers.BatchNormalization()(x2)\n",
        "    x2 = tf.keras.layers.Dropout(0.3)(x2)\n",
        "\n",
        "    # Combinación\n",
        "    combined = tf.keras.layers.concatenate([x1, x2])\n",
        "\n",
        "    x = tf.keras.layers.Dense(256, activation='relu')(combined)\n",
        "    x = tf.keras.layers.BatchNormalization()(x)\n",
        "    x = tf.keras.layers.Dropout(0.3)(x)\n",
        "    x = tf.keras.layers.Dense(128, activation='relu')(x)\n",
        "    x = tf.keras.layers.BatchNormalization()(x)\n",
        "    x = tf.keras.layers.Dropout(0.2)(x)\n",
        "\n",
        "    output = tf.keras.layers.Dense(1)(x)\n",
        "\n",
        "    model = tf.keras.Model(inputs=[raw_input, wavelet_input], outputs=output)\n",
        "    return model\n",
        "\n",
        "input_shape_raw = (X_raw_train.shape[1], 1)\n",
        "input_shape_wavelets = (X_wavelets_train.shape[1],)\n",
        "\n",
        "model = create_model(input_shape_raw, input_shape_wavelets)\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
        "\n",
        "model.compile(\n",
        "    optimizer=optimizer,\n",
        "    loss='mse',\n",
        "    metrics=['mae', 'mse']\n",
        ")\n",
        "\n",
        "model.summary()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f2201de4",
      "metadata": {
        "id": "f2201de4"
      },
      "outputs": [],
      "source": [
        "# ------------------- Callbacks -------------------\n",
        "callbacks = [\n",
        "    tf.keras.callbacks.EarlyStopping(monitor='val_mae', patience=15, restore_best_weights=True, mode='min'),\n",
        "    tf.keras.callbacks.ReduceLROnPlateau(monitor='val_mae', factor=0.5, patience=5, min_lr=1e-6, mode='min'),\n",
        "    tf.keras.callbacks.ModelCheckpoint(filepath='best_model.h5', monitor='val_mae', save_best_only=True, mode='min')\n",
        "]\n",
        "\n",
        "# ------------------- Entrenamiento -------------------\n",
        "history = model.fit(\n",
        "    [X_raw_train, X_wavelets_train],\n",
        "    y_train,\n",
        "    validation_data=([X_raw_val, X_wavelets_val], y_val),\n",
        "    epochs=100,\n",
        "    batch_size=32,\n",
        "    callbacks=callbacks,\n",
        "    verbose=1\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "83656eb1",
      "metadata": {
        "id": "83656eb1"
      },
      "outputs": [],
      "source": [
        "# ------------------- Evaluación -------------------\n",
        "print('Realizando predicciones en conjunto de prueba...')\n",
        "y_pred = model.predict([X_raw_test, X_wavelets_test])\n",
        "\n",
        "# Guardar resultados\n",
        "results_df = pd.DataFrame({\n",
        "    'file': test_files['file'],\n",
        "    'real_time': y_test,\n",
        "    'predicted_time': y_pred.flatten(),\n",
        "    'error': y_pred.flatten() - y_test\n",
        "})\n",
        "\n",
        "results_df['abs_error'] = np.abs(results_df['error'])\n",
        "results_df = results_df.sort_values('abs_error', ascending=False)\n",
        "\n",
        "results_df.to_csv(os.path.join(features_path, 'model_evaluation_results.csv'), index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "05ced207",
      "metadata": {
        "id": "05ced207"
      },
      "outputs": [],
      "source": [
        "# ------------------- Métricas Finales -------------------\n",
        "print('\\nMétricas de rendimiento en conjunto de prueba:')\n",
        "mae = np.mean(np.abs(results_df['error']))\n",
        "rmse = np.sqrt(np.mean(results_df['error']**2))\n",
        "max_error = np.max(results_df['abs_error'])\n",
        "\n",
        "print(f'MAE: {mae:.4f} segundos')\n",
        "print(f'RMSE: {rmse:.4f} segundos')\n",
        "print(f'Máximo error: {max_error:.4f} segundos')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4dcb5b92",
      "metadata": {
        "id": "4dcb5b92"
      },
      "outputs": [],
      "source": [
        "# ------------------- Visualización -------------------\n",
        "errors = y_pred.flatten() - y_test\n",
        "\n",
        "plt.figure(figsize=(12, 5))\n",
        "\n",
        "# Histograma de errores\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.hist(errors, bins=50, edgecolor='black')\n",
        "plt.title('Distribución de errores')\n",
        "plt.xlabel('Error (segundos)')\n",
        "plt.ylabel('Frecuencia')\n",
        "plt.axvline(x=0, color='r', linestyle='--', label='Error cero')\n",
        "plt.legend()\n",
        "\n",
        "# Scatter plot\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.scatter(y_test, y_pred.flatten(), alpha=0.5)\n",
        "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--')\n",
        "plt.xlabel('Tiempo real (s)')\n",
        "plt.ylabel('Tiempo predicho (s)')\n",
        "plt.title('Predicción vs Real')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Estadísticas adicionales\n",
        "print('\\nEstadísticas de errores:')\n",
        "print(f'Error medio: {np.mean(errors):.4f} segundos')\n",
        "print(f'Desviación estándar: {np.std(errors):.4f} segundos')\n",
        "print(f'Mediana del error: {np.median(errors):.4f} segundos')\n",
        "print(f'Error dentro de ±0.5s: {100*np.mean(np.abs(errors) < 0.5):.1f}%')\n",
        "print(f'Error dentro de ±1.0s: {100*np.mean(np.abs(errors) < 1.0):.1f}%')"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.10"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}