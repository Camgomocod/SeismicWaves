{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "926a39c2",
   "metadata": {},
   "source": [
    "# Training Model: Cnn + wavelets transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99d53813",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-27 17:02:05.868912: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1745791326.120781  287014 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1745791326.195619  287014 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1745791326.808155  287014 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1745791326.808186  287014 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1745791326.808187  287014 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1745791326.808189  287014 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-04-27 17:02:06.870415: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from obspy import read\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4029eab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_path = '/ruta/a/train'\n",
    "val_data_path = '/ruta/a/val'\n",
    "test_data_path = '/ruta/a/test'\n",
    "features_path = '/ruta/a/features'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ad52981",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ------------------- Funciones de Carga -------------------\n",
    "def load_data(data_path):\n",
    "    # Cargar señales crudas\n",
    "    raw_signals = []\n",
    "    files_df = pd.read_csv(os.path.join(data_path, 'feature_files.csv'))\n",
    "    print(f'Cargando señales desde {data_path}...')\n",
    "    for file in tqdm(files_df['file']):\n",
    "        file_path = os.path.join(data_path, 'augmented', file)\n",
    "        st = read(file_path)\n",
    "        signal = st[0].data\n",
    "        raw_signals.append(signal)\n",
    "\n",
    "    X_raw = np.array(raw_signals)\n",
    "    X_raw = X_raw.reshape(X_raw.shape[0], -1, 1)  # Añadir dimensión para CNN\n",
    "\n",
    "    # Cargar características wavelets\n",
    "    X_wavelets = np.load(os.path.join(data_path, 'wavelet_features.npy'))\n",
    "    \n",
    "    # Cargar tiempos de llegada\n",
    "    y = np.load(os.path.join(data_path, 'arrival_times.npy'))\n",
    "    \n",
    "    return X_raw, X_wavelets, y, files_df\n",
    "\n",
    "# ------------------- Carga de Datos -------------------\n",
    "X_raw_train, X_wavelets_train, y_train, train_files = load_data(train_data_path)\n",
    "X_raw_val, X_wavelets_val, y_val, val_files = load_data(val_data_path)\n",
    "X_raw_test, X_wavelets_test, y_test, test_files = load_data(test_data_path)\n",
    "\n",
    "print('Formas:')\n",
    "print(f'Entrenamiento señales crudas: {X_raw_train.shape}')\n",
    "print(f'Validación señales crudas: {X_raw_val.shape}')\n",
    "print(f'Prueba señales crudas: {X_raw_test.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "effc50e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------- Creación del Modelo -------------------\n",
    "def create_model(input_shape_raw, input_shape_wavelets):\n",
    "    # Entrada de señales crudas\n",
    "    raw_input = tf.keras.layers.Input(shape=input_shape_raw)\n",
    "    x1 = tf.keras.layers.BatchNormalization()(raw_input)\n",
    "    x1 = tf.keras.layers.Conv1D(32, 5, padding='same', activation='relu')(x1)\n",
    "    x1 = tf.keras.layers.BatchNormalization()(x1)\n",
    "    x1 = tf.keras.layers.MaxPooling1D(2)(x1)\n",
    "    x1 = tf.keras.layers.Conv1D(64, 5, padding='same', activation='relu')(x1)\n",
    "    x1 = tf.keras.layers.BatchNormalization()(x1)\n",
    "    x1 = tf.keras.layers.MaxPooling1D(2)(x1)\n",
    "    x1 = tf.keras.layers.Conv1D(128, 5, padding='same', activation='relu')(x1)\n",
    "    x1 = tf.keras.layers.BatchNormalization()(x1)\n",
    "    x1 = tf.keras.layers.GlobalAveragePooling1D()(x1)\n",
    "\n",
    "    # Entrada de características wavelets\n",
    "    wavelet_input = tf.keras.layers.Input(shape=input_shape_wavelets)\n",
    "    x2 = tf.keras.layers.BatchNormalization()(wavelet_input)\n",
    "    x2 = tf.keras.layers.Dense(128, activation='relu')(x2)\n",
    "    x2 = tf.keras.layers.BatchNormalization()(x2)\n",
    "    x2 = tf.keras.layers.Dropout(0.3)(x2)\n",
    "\n",
    "    # Combinación\n",
    "    combined = tf.keras.layers.concatenate([x1, x2])\n",
    "\n",
    "    x = tf.keras.layers.Dense(256, activation='relu')(combined)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.Dropout(0.3)(x)\n",
    "    x = tf.keras.layers.Dense(128, activation='relu')(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.Dropout(0.2)(x)\n",
    "\n",
    "    output = tf.keras.layers.Dense(1)(x)\n",
    "\n",
    "    model = tf.keras.Model(inputs=[raw_input, wavelet_input], outputs=output)\n",
    "    return model\n",
    "\n",
    "input_shape_raw = (X_raw_train.shape[1], 1)\n",
    "input_shape_wavelets = (X_wavelets_train.shape[1],)\n",
    "\n",
    "model = create_model(input_shape_raw, input_shape_wavelets)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "\n",
    "model.compile(\n",
    "    optimizer=optimizer,\n",
    "    loss='mse',\n",
    "    metrics=['mae', 'mse']\n",
    ")\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2201de4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------- Callbacks -------------------\n",
    "callbacks = [\n",
    "    tf.keras.callbacks.EarlyStopping(monitor='val_mae', patience=15, restore_best_weights=True, mode='min'),\n",
    "    tf.keras.callbacks.ReduceLROnPlateau(monitor='val_mae', factor=0.5, patience=5, min_lr=1e-6, mode='min'),\n",
    "    tf.keras.callbacks.ModelCheckpoint(filepath='best_model.h5', monitor='val_mae', save_best_only=True, mode='min')\n",
    "]\n",
    "\n",
    "# ------------------- Entrenamiento -------------------\n",
    "history = model.fit(\n",
    "    [X_raw_train, X_wavelets_train],\n",
    "    y_train,\n",
    "    validation_data=([X_raw_val, X_wavelets_val], y_val),\n",
    "    epochs=100,\n",
    "    batch_size=32,\n",
    "    callbacks=callbacks,\n",
    "    verbose=1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83656eb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------- Evaluación -------------------\n",
    "print('Realizando predicciones en conjunto de prueba...')\n",
    "y_pred = model.predict([X_raw_test, X_wavelets_test])\n",
    "\n",
    "# Guardar resultados\n",
    "results_df = pd.DataFrame({\n",
    "    'file': test_files['file'],\n",
    "    'real_time': y_test,\n",
    "    'predicted_time': y_pred.flatten(),\n",
    "    'error': y_pred.flatten() - y_test\n",
    "})\n",
    "\n",
    "results_df['abs_error'] = np.abs(results_df['error'])\n",
    "results_df = results_df.sort_values('abs_error', ascending=False)\n",
    "\n",
    "results_df.to_csv(os.path.join(features_path, 'model_evaluation_results.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05ced207",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------- Métricas Finales -------------------\n",
    "print('\\nMétricas de rendimiento en conjunto de prueba:')\n",
    "mae = np.mean(np.abs(results_df['error']))\n",
    "rmse = np.sqrt(np.mean(results_df['error']**2))\n",
    "max_error = np.max(results_df['abs_error'])\n",
    "\n",
    "print(f'MAE: {mae:.4f} segundos')\n",
    "print(f'RMSE: {rmse:.4f} segundos')\n",
    "print(f'Máximo error: {max_error:.4f} segundos')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dcb5b92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------- Visualización -------------------\n",
    "errors = y_pred.flatten() - y_test\n",
    "\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "# Histograma de errores\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.hist(errors, bins=50, edgecolor='black')\n",
    "plt.title('Distribución de errores')\n",
    "plt.xlabel('Error (segundos)')\n",
    "plt.ylabel('Frecuencia')\n",
    "plt.axvline(x=0, color='r', linestyle='--', label='Error cero')\n",
    "plt.legend()\n",
    "\n",
    "# Scatter plot\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.scatter(y_test, y_pred.flatten(), alpha=0.5)\n",
    "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--')\n",
    "plt.xlabel('Tiempo real (s)')\n",
    "plt.ylabel('Tiempo predicho (s)')\n",
    "plt.title('Predicción vs Real')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Estadísticas adicionales\n",
    "print('\\nEstadísticas de errores:')\n",
    "print(f'Error medio: {np.mean(errors):.4f} segundos')\n",
    "print(f'Desviación estándar: {np.std(errors):.4f} segundos')\n",
    "print(f'Mediana del error: {np.median(errors):.4f} segundos')\n",
    "print(f'Error dentro de ±0.5s: {100*np.mean(np.abs(errors) < 0.5):.1f}%')\n",
    "print(f'Error dentro de ±1.0s: {100*np.mean(np.abs(errors) < 1.0):.1f}%')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wavePredict",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
