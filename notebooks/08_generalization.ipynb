{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d9639833",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-05 17:14:13.697193: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1746483253.711317   36866 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1746483253.715398   36866 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1746483253.725186   36866 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1746483253.725202   36866 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1746483253.725203   36866 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1746483253.725204   36866 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-05-05 17:14:13.728687: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import pandas as pd\n",
    "from obspy import read\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dac777a0",
   "metadata": {},
   "source": [
    "#hola"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1860235d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Forzar uso de CPU (opcional)\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '-1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a1a8aca3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-05 16:15:50.589569: E external/local_xla/xla/stream_executor/cuda/cuda_platform.cc:51] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: UNKNOWN ERROR (303)\n"
     ]
    }
   ],
   "source": [
    "# Ruta al modelo guardado\n",
    "model_path = '/mnt/c/Users/Usuario/Documents/Studies/GicoProject/SeismicWaves/src/models/augmented_ranges_huber_data.keras'\n",
    "\n",
    "# Cargar el modelo entrenado\n",
    "model = tf.keras.models.load_model(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "91324965",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_or_trim(signal, target_length=8000):\n",
    "    if len(signal) > target_length:\n",
    "        return signal[:target_length]\n",
    "    elif len(signal) < target_length:\n",
    "        pad_width = target_length - len(signal)\n",
    "        return np.pad(signal, (0, pad_width), mode='constant')\n",
    "    return signal\n",
    "\n",
    "def load_inference_data(data_path):\n",
    "    raw_signals = []\n",
    "    files_df = pd.read_csv(os.path.join(data_path, 'feature_files.csv'))\n",
    "    \n",
    "    print(f'Cargando señales desde {data_path}...')\n",
    "    for file in tqdm(files_df['file']):\n",
    "        file_path = os.path.join(data_path, file)\n",
    "        st = read(file_path)\n",
    "        signal = st[0].data\n",
    "        signal = pad_or_trim(signal)      # Luego pad/trim\n",
    "        raw_signals.append(signal)\n",
    "\n",
    "    X_raw = np.array(raw_signals)\n",
    "    X_raw = X_raw.reshape(X_raw.shape[0], -1, 1)\n",
    "\n",
    "    # Cargar características wavelets\n",
    "    X_wavelets = np.load(os.path.join(data_path, 'wavelet_features.npy'))\n",
    "\n",
    "    return X_raw, X_wavelets, files_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4f0455cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cargando señales desde /mnt/c/Users/Usuario/Documents/Studies/GicoProject/SeismicWaves/data/procesed/used_data/testing...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cargando señales desde /mnt/c/Users/Usuario/Documents/Studies/GicoProject/SeismicWaves/data/procesed/used_data/testing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 496/496 [00:26<00:00, 18.76it/s]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cargando señales desde /mnt/c/Users/Usuario/Documents/Studies/GicoProject/SeismicWaves/data/procesed/used_data/testing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 496/496 [00:26<00:00, 18.76it/s]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Realizando predicciones...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cargando señales desde /mnt/c/Users/Usuario/Documents/Studies/GicoProject/SeismicWaves/data/procesed/used_data/testing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 496/496 [00:26<00:00, 18.76it/s]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Realizando predicciones...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1746479809.217057   21673 service.cc:152] XLA service 0x7f1f9400f160 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1746479809.217110   21673 service.cc:160]   StreamExecutor device (0): Host, Default Version\n",
      "2025-05-05 16:16:49.227546: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cargando señales desde /mnt/c/Users/Usuario/Documents/Studies/GicoProject/SeismicWaves/data/procesed/used_data/testing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 496/496 [00:26<00:00, 18.76it/s]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Realizando predicciones...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1746479809.217057   21673 service.cc:152] XLA service 0x7f1f9400f160 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1746479809.217110   21673 service.cc:160]   StreamExecutor device (0): Host, Default Version\n",
      "2025-05-05 16:16:49.227546: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m 2/16\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 96ms/step "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cargando señales desde /mnt/c/Users/Usuario/Documents/Studies/GicoProject/SeismicWaves/data/procesed/used_data/testing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 496/496 [00:26<00:00, 18.76it/s]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Realizando predicciones...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1746479809.217057   21673 service.cc:152] XLA service 0x7f1f9400f160 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1746479809.217110   21673 service.cc:160]   StreamExecutor device (0): Host, Default Version\n",
      "2025-05-05 16:16:49.227546: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m 2/16\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 96ms/step "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1746479809.469570   21673 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cargando señales desde /mnt/c/Users/Usuario/Documents/Studies/GicoProject/SeismicWaves/data/procesed/used_data/testing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 496/496 [00:26<00:00, 18.76it/s]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Realizando predicciones...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1746479809.217057   21673 service.cc:152] XLA service 0x7f1f9400f160 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1746479809.217110   21673 service.cc:160]   StreamExecutor device (0): Host, Default Version\n",
      "2025-05-05 16:16:49.227546: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m 2/16\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 96ms/step "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1746479809.469570   21673 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 118ms/step\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 118ms/step\n",
      "Resultados guardados en: /mnt/c/Users/Usuario/Documents/Studies/GicoProject/SeismicWaves/data/procesed/used_data/predictions.csv\n",
      "Resultados guardados en: /mnt/c/Users/Usuario/Documents/Studies/GicoProject/SeismicWaves/data/procesed/used_data/predictions.csv\n"
     ]
    }
   ],
   "source": [
    "# Definir la ruta al directorio con los datos a procesar\n",
    "inference_path = '/mnt/c/Users/Usuario/Documents/Studies/GicoProject/SeismicWaves/data/procesed/used_data/testing'\n",
    "\n",
    "# Cargar datos\n",
    "X_raw, X_wavelets, files_df = load_inference_data(inference_path)\n",
    "\n",
    "# Realizar predicciones\n",
    "print('Realizando predicciones...')\n",
    "predictions = model.predict([X_raw, X_wavelets])\n",
    "\n",
    "# Crear DataFrame con resultados\n",
    "results_df = pd.DataFrame({\n",
    "    'file': files_df['file'],\n",
    "    'predicted_time': predictions.flatten()\n",
    "})\n",
    "\n",
    "# Guardar resultados\n",
    "output_path = os.path.join(os.path.dirname(inference_path), 'predictions.csv')\n",
    "results_df.to_csv(output_path, index=False)\n",
    "print(f'Resultados guardados en: {output_path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "76f80b33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cargando señales desde /mnt/c/Users/Usuario/Documents/Studies/GicoProject/SeismicWaves/data/raw/process/testing_filtered...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cargando señales desde /mnt/c/Users/Usuario/Documents/Studies/GicoProject/SeismicWaves/data/raw/process/testing_filtered...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 790/790 [00:27<00:00, 28.64it/s]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cargando señales desde /mnt/c/Users/Usuario/Documents/Studies/GicoProject/SeismicWaves/data/raw/process/testing_filtered...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 790/790 [00:27<00:00, 28.64it/s]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Realizando predicciones...\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 86ms/step\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 86ms/step\n",
      "Resultados guardados en: /mnt/c/Users/Usuario/Documents/Studies/GicoProject/SeismicWaves/data/raw/process/predictions_eval.csv\n",
      "Resultados guardados en: /mnt/c/Users/Usuario/Documents/Studies/GicoProject/SeismicWaves/data/raw/process/predictions_eval.csv\n"
     ]
    }
   ],
   "source": [
    "# Definir la ruta al directorio con los datos a procesar\n",
    "inference_path = '/mnt/c/Users/Usuario/Documents/Studies/GicoProject/SeismicWaves/data/raw/process/testing_filtered'\n",
    "\n",
    "# Cargar datos\n",
    "X_raw, X_wavelets, files_df = load_inference_data(inference_path)\n",
    "\n",
    "# Realizar predicciones\n",
    "print('Realizando predicciones...')\n",
    "predictions = model.predict([X_raw, X_wavelets])\n",
    "\n",
    "# Crear DataFrame con resultados\n",
    "results_df = pd.DataFrame({\n",
    "    'file': files_df['file'],\n",
    "    'predicted_time': predictions.flatten()\n",
    "})\n",
    "\n",
    "# Guardar resultados\n",
    "output_path = os.path.join(os.path.dirname(inference_path), 'predictions_eval.csv')\n",
    "results_df.to_csv(output_path, index=False)\n",
    "print(f'Resultados guardados en: {output_path}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2adcc08b",
   "metadata": {},
   "source": [
    "## Convert Predictions to UNIX Timestamps\n",
    "\n",
    "Convert predictions to UNIX timestamps (seconds since epoch) to match training data format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e183bac2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First few predictions:\n",
      "       file         lec_p\n",
      "0  01011426  1.704137e+09\n",
      "1  01020023  1.704173e+09\n",
      "2  01020428  1.704188e+09\n",
      "3  01020441  1.704188e+09\n",
      "4  01020453  1.704189e+09\n"
     ]
    }
   ],
   "source": [
    "# Read predictions file\n",
    "pred_path = '/mnt/c/Users/Usuario/Documents/Studies/GicoProject/SeismicWaves/data/raw/process/predictions_eval.csv'\n",
    "predictions_df = pd.read_csv(pred_path)\n",
    "\n",
    "# Extract date components from filenames\n",
    "def extract_datetime(filename):\n",
    "    # Remove .mseed extension and get date/time digits\n",
    "    datetime_str = filename.replace('.mseed', '')\n",
    "    \n",
    "    # Extract components\n",
    "    month = int(datetime_str[0:2])\n",
    "    day = int(datetime_str[2:4])\n",
    "    hour = int(datetime_str[4:6])\n",
    "    minute = int(datetime_str[6:8])\n",
    "    \n",
    "    # Construct datetime - use 2024 as base year\n",
    "    from datetime import datetime\n",
    "    return datetime(2024, month, day, hour, minute)\n",
    "\n",
    "# Convert to UNIX timestamps\n",
    "predictions_df['base_timestamp'] = predictions_df['file'].apply(lambda x: extract_datetime(x).timestamp())\n",
    "predictions_df['lec_p'] = predictions_df['base_timestamp'] + predictions_df['predicted_time']\n",
    "\n",
    "# Create output dataframe in required format\n",
    "result_df = pd.DataFrame()\n",
    "result_df['file'] = predictions_df['file'].str.replace('.mseed','')\n",
    "result_df['lec_p'] = predictions_df['lec_p']\n",
    "\n",
    "# Save results\n",
    "output_path = '/mnt/c/Users/Usuario/Documents/Studies/GicoProject/SeismicWaves/data/raw/process/predictions_eval_timestampsv5.csv'\n",
    "result_df.to_csv(output_path, index=False)\n",
    "\n",
    "print(f\"First few predictions:\")\n",
    "print(result_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b09736d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wavePredict",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
